{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0668629e-f135-4a79-8d39-12fda9b1781c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: v2.2.2\n",
      "pandas: v2.2.1\n",
      "numpy: v1.26.4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(f\"torch: v{torch.__version__}\\npandas: v{pd.__version__}\\nnumpy: v{np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dee809-ee80-413d-ad8c-b8d0e00113b0",
   "metadata": {},
   "source": [
    "## Inroduction to Tensors\n",
    "\n",
    "### Creating Tensors\n",
    "\n",
    "https://pytorch.org/docs/stable/tensors.html\n",
    "\n",
    "![Scalar|Vector|Matrix|Tensor](images/svmt.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7e088f67-9441-4302-a209-6760bddc6886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar - a single number\n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "162dc08a-6fc0-4b30-a48d-cbcce112eae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c03e6518-08f5-4f27-b1a1-27d87cd68350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0dc76928-0264-44da-9d3c-46f1ff76c389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector - a number with direction (e.g. wind speed with direction) but can also have many other numbers\n",
    "\n",
    "vector = torch.tensor([7,7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "231b5c96-6a19-4fb9-abd4-7342d175d688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2c356c0f-fed0-42b0-bbaf-ab780118290b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9886f7f3-a13f-4cea-9104-775531ac69e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MATRIX - a 2-dimensional array of numbers\n",
    "MATRIX = torch.tensor([\n",
    "    [7,8],\n",
    "    [9,10]\n",
    "])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9c2d7f89-8cb6-40d4-819d-d0049793c82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "89b8d598-1dea-4a56-aca9-020acff27ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a36e7a62-ac9b-474d-905b-0b4d7a88fb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3],\n",
       "         [ 4,  5,  6],\n",
       "         [ 7,  8,  9],\n",
       "         [11, 12, 13]]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TENSOR - an n-dimensional array of numbers\n",
    "TENSOR = torch.tensor([[\n",
    "    [1,2,3],\n",
    "    [4,5,6],\n",
    "    [7,8,9],\n",
    "    [11,12,13],\n",
    "]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "43a13c5b-9b12-4fd0-9cc0-c9b2e2f1b105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "80730047-e05a-450a-ba88-8540b0fc5407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 3])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9857d794-97ca-45f3-b919-17fab13e15d7",
   "metadata": {},
   "source": [
    "# Scalar | Vector | Matrix | Tensor\n",
    "![Scalar|Vector|Matrix|Tensor](images/00-scalar-vector-matrix-tensor.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c21948c9-db05-4a01-9665-97ec75151ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, torch.Size([2, 3, 4]))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(2, 3, 4)\n",
    "random_tensor.ndim, random_tensor.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ae88bc86-03c0-46b8-977b-50870a536747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3531, 0.7719, 0.8001, 0.4619],\n",
       "        [0.7602, 0.7689, 0.8622, 0.0168],\n",
       "        [0.8253, 0.7856, 0.9128, 0.1724]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "00ef3df8-e9de-449e-9dc7-c2c0c1ad7a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor(1))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range_of_number = torch.arange(0, 10)\n",
    "range_of_number, range_of_number[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3abe6a03-2a4f-4e64-a5e8-641fde041c72",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3., 6., 9.]),\n",
       " torch.float32,\n",
       " device(type='cpu'),\n",
       " False,\n",
       " torch.Size([3]),\n",
       " torch.Size([3]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float 32 tensor\n",
    "float_32_tensor = torch.tensor(\n",
    "    [3.0, 6.0, 9.0],\n",
    "    dtype=torch.float32,\n",
    "    device='cpu',\n",
    "    requires_grad=False)\n",
    "\n",
    "(\n",
    "    float_32_tensor,\n",
    "    float_32_tensor.dtype,\n",
    "    float_32_tensor.device,\n",
    "    float_32_tensor.requires_grad,\n",
    "    float_32_tensor.shape,\n",
    "    float_32_tensor.size(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6aa0bbbe-c090-4af3-ae71-e31424a67537",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3., 6., 9.], dtype=torch.float16),\n",
       " torch.float16,\n",
       " device(type='cpu'),\n",
       " False,\n",
       " torch.Size([3]),\n",
       " torch.Size([3]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.float16)\n",
    "\n",
    "(\n",
    "    float_16_tensor,\n",
    "    float_16_tensor.dtype,\n",
    "    float_16_tensor.device,\n",
    "    float_16_tensor.requires_grad,\n",
    "    float_16_tensor.shape,\n",
    "    float_16_tensor.size(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3b67adb9-40dd-4f7e-800b-d71ab058e758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor * float_32_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ef17a1-9335-4e87-81fd-4b603bf48ab6",
   "metadata": {},
   "source": [
    "### Manipulation Tensors (tensor operation)\n",
    "\n",
    "* Addition\n",
    "* Subtraction\n",
    "* Division\n",
    "* Multiplacation (element-wise)\n",
    "* Matrix Multiplication\n",
    "\n",
    "#### The main two rules for matrix multiplication to remember are:\n",
    "\n",
    "1. The inner dimensions must match:\n",
    "(3, 2) @ (3, 2) won't work\n",
    "(2, 3) @ (3, 2) will work\n",
    "(3, 2) @ (2, 3) will work\n",
    "\n",
    "2. The resulting matrix has the shape of the outer dimensions:\n",
    "(2, 3) @ (3, 2) -> (2, 2)\n",
    "(3, 2) @ (2, 3) -> (3, 3)\n",
    "\n",
    "\n",
    "![Matrix Multiplacation](images/matrix-multiplication.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "849f77a0-7867-4a7b-8780-60d2fef0d5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[140, 146],\n",
       "        [320, 335]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_a = torch.tensor([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "])\n",
    "\n",
    "matrix_b = torch.tensor([\n",
    "    [10, 11],\n",
    "    [20, 21],\n",
    "    [30, 31],\n",
    "])\n",
    "\n",
    "matrix_ab = torch.matmul(matrix_a, matrix_b)\n",
    "matrix_ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2533edb6-f152-4415-9a7b-8e0e82bae20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
      "\n",
      "New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])\n",
      "\n",
      "Multiplying: torch.Size([3, 2]) * torch.Size([2, 3]) <- inner dimensions match\n",
      "\n",
      "Output:\n",
      "\n",
      "tensor([[ 27.,  30.,  33.],\n",
      "        [ 61.,  68.,  75.],\n",
      "        [ 95., 106., 117.]])\n",
      "\n",
      "Output shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Shapes need to be in the right way  \n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]], dtype=torch.float32)\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                         [8, 11], \n",
    "                         [9, 12]], dtype=torch.float32)\n",
    "# The operation works when tensor_B is transposed\n",
    "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\")\n",
    "print(f\"New shapes: tensor_A = {tensor_A.shape} (same as above), tensor_B.T = {tensor_B.T.shape}\\n\")\n",
    "print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape} <- inner dimensions match\\n\")\n",
    "print(\"Output:\\n\")\n",
    "output = torch.matmul(tensor_A, tensor_B.T)\n",
    "print(output) \n",
    "print(f\"\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f059e4-7585-4118-ba37-c0a7c13d7082",
   "metadata": {},
   "source": [
    "### Reshaping, stacking, squeezing and unsqueezing\n",
    "Often times you'll want to reshape or change the dimensions of your tensors without actually changing the values inside them.\n",
    "\n",
    "To do so, some popular methods are:\n",
    "\n",
    "| Method                        | One-line description                                                                                        |\n",
    "|-------------------------------|-------------------------------------------------------------------------------------------------------------|\n",
    "| `torch.reshape(input, shape)` | Reshapes input to shape (if compatible), can also use torch.Tensor.reshape().                               |\n",
    "| `Tensor.view(shape)`          | Returns a view of the original tensor in a different shape but shares the same data as the original tensor. |\n",
    "| `torch.stack(tensors, dim=0)` | Concatenates a sequence of tensors along a new dimension (dim), all tensors must be same size.              |\n",
    "| `torch.squeeze(input)`        | Squeezes input to remove all the dimenions with value 1.                                                    |\n",
    "| `torch.unsqueeze(input, dim)` | Returns input with a dimension value of 1 added at dim.                                                     |\n",
    "| `torch.permute(input, dims)`  | Returns a view of the original input with its dimensions permuted (rearranged) to dims.                     |\n",
    "\n",
    "Why do any of these?\n",
    "\n",
    "Because deep learning models (neural networks) are all about manipulating tensors in some way. And because of the rules of matrix multiplication, if you've got shape mismatches, you'll run into errors. These methods help you make sure the right elements of your tensors are mixing with the right elements of other tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f15635c2-749b-47ce-ae1b-eb1104c6d0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,  11.,\n",
       "          12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.,  21.,  22.,  23.,\n",
       "          24.,  25.,  26.,  27.,  28.,  29.,  30.,  31.,  32.,  33.,  34.,  35.,\n",
       "          36.,  37.,  38.,  39.,  40.,  41.,  42.,  43.,  44.,  45.,  46.,  47.,\n",
       "          48.,  49.,  50.,  51.,  52.,  53.,  54.,  55.,  56.,  57.,  58.,  59.,\n",
       "          60.,  61.,  62.,  63.,  64.,  65.,  66.,  67.,  68.,  69.,  70.,  71.,\n",
       "          72.,  73.,  74.,  75.,  76.,  77.,  78.,  79.,  80.,  81.,  82.,  83.,\n",
       "          84.,  85.,  86.,  87.,  88.,  89.,  90.,  91.,  92.,  93.,  94.,  95.,\n",
       "          96.,  97.,  98.,  99., 100., 101., 102., 103., 104., 105., 106., 107.,\n",
       "         108., 109., 110., 111., 112., 113., 114., 115., 116., 117., 118., 119.]),\n",
       " torch.Size([120]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Torch Reshape - https://pytorch.org/docs/stable/generated/torch.reshape.html\n",
    "x = torch.arange(120.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8ce262c2-8118-489e-8728-f72aa8c70f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[  0.,   1.,   2.,   3.,   4.],\n",
       "           [  5.,   6.,   7.,   8.,   9.],\n",
       "           [ 10.,  11.,  12.,  13.,  14.],\n",
       "           [ 15.,  16.,  17.,  18.,  19.]],\n",
       " \n",
       "          [[ 20.,  21.,  22.,  23.,  24.],\n",
       "           [ 25.,  26.,  27.,  28.,  29.],\n",
       "           [ 30.,  31.,  32.,  33.,  34.],\n",
       "           [ 35.,  36.,  37.,  38.,  39.]],\n",
       " \n",
       "          [[ 40.,  41.,  42.,  43.,  44.],\n",
       "           [ 45.,  46.,  47.,  48.,  49.],\n",
       "           [ 50.,  51.,  52.,  53.,  54.],\n",
       "           [ 55.,  56.,  57.,  58.,  59.]]],\n",
       " \n",
       " \n",
       "         [[[ 60.,  61.,  62.,  63.,  64.],\n",
       "           [ 65.,  66.,  67.,  68.,  69.],\n",
       "           [ 70.,  71.,  72.,  73.,  74.],\n",
       "           [ 75.,  76.,  77.,  78.,  79.]],\n",
       " \n",
       "          [[ 80.,  81.,  82.,  83.,  84.],\n",
       "           [ 85.,  86.,  87.,  88.,  89.],\n",
       "           [ 90.,  91.,  92.,  93.,  94.],\n",
       "           [ 95.,  96.,  97.,  98.,  99.]],\n",
       " \n",
       "          [[100., 101., 102., 103., 104.],\n",
       "           [105., 106., 107., 108., 109.],\n",
       "           [110., 111., 112., 113., 114.],\n",
       "           [115., 116., 117., 118., 119.]]]]),\n",
       " torch.Size([2, 3, 4, 5]))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Torch Reshape - https://pytorch.org/docs/stable/generated/torch.reshape.html\n",
    "x_reshaped = torch.reshape(x, (2, 3, 4, 5))\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "64687c50-1566-4fb4-96d2-8a1aa9161867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,  11.,\n",
       "           12.,  13.,  14.],\n",
       "         [ 15.,  16.,  17.,  18.,  19.,  20.,  21.,  22.,  23.,  24.,  25.,  26.,\n",
       "           27.,  28.,  29.],\n",
       "         [ 30.,  31.,  32.,  33.,  34.,  35.,  36.,  37.,  38.,  39.,  40.,  41.,\n",
       "           42.,  43.,  44.],\n",
       "         [ 45.,  46.,  47.,  48.,  49.,  50.,  51.,  52.,  53.,  54.,  55.,  56.,\n",
       "           57.,  58.,  59.],\n",
       "         [ 60.,  61.,  62.,  63.,  64.,  65.,  66.,  67.,  68.,  69.,  70.,  71.,\n",
       "           72.,  73.,  74.],\n",
       "         [ 75.,  76.,  77.,  78.,  79.,  80.,  81.,  82.,  83.,  84.,  85.,  86.,\n",
       "           87.,  88.,  89.],\n",
       "         [ 90.,  91.,  92.,  93.,  94.,  95.,  96.,  97.,  98.,  99., 100., 101.,\n",
       "          102., 103., 104.],\n",
       "         [105., 106., 107., 108., 109., 110., 111., 112., 113., 114., 115., 116.,\n",
       "          117., 118., 119.]]),\n",
       " torch.Size([8, 15]))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://pytorch.org/docs/stable/generated/torch.Tensor.view.html\n",
    "x_view = x_reshaped.view(8, 15)\n",
    "x_view, x_view.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b53085f8-ea58-4a24-b3be-d7c5d882b5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,  11.,\n",
       "           12.,  13.,  14.],\n",
       "         [ 15.,  16.,  17.,  18.,  19.,  20.,  21.,  22.,  23.,  24.,  25.,  26.,\n",
       "           27.,  28.,  29.],\n",
       "         [ 30.,  31.,  32.,  33.,  34.,  35.,  36.,  37.,  38.,  39.,  40.,  41.,\n",
       "           42.,  43.,  44.],\n",
       "         [ 45.,  46.,  47.,  48.,  49.,  50.,  51.,  52.,  53.,  54.,  55.,  56.,\n",
       "           57.,  58.,  59.],\n",
       "         [ 60.,  61.,  62.,  63.,  64.,  65.,  66.,  67.,  68.,  69.,  70.,  71.,\n",
       "           72.,  73.,  74.],\n",
       "         [ 75.,  76.,  77.,  78.,  79.,  80.,  81.,  82.,  83.,  84.,  85.,  86.,\n",
       "           87.,  88.,  89.],\n",
       "         [ 90.,  91.,  92.,  93.,  94.,  95.,  96.,  97.,  98.,  99., 100., 101.,\n",
       "          102., 103., 104.],\n",
       "         [105., 106., 107., 108., 109., 110., 111., 112., 113., 114., 115., 116.,\n",
       "          117., 118., 420.]]),\n",
       " tensor([[[[  0.,   1.,   2.,   3.,   4.],\n",
       "           [  5.,   6.,   7.,   8.,   9.],\n",
       "           [ 10.,  11.,  12.,  13.,  14.],\n",
       "           [ 15.,  16.,  17.,  18.,  19.]],\n",
       " \n",
       "          [[ 20.,  21.,  22.,  23.,  24.],\n",
       "           [ 25.,  26.,  27.,  28.,  29.],\n",
       "           [ 30.,  31.,  32.,  33.,  34.],\n",
       "           [ 35.,  36.,  37.,  38.,  39.]],\n",
       " \n",
       "          [[ 40.,  41.,  42.,  43.,  44.],\n",
       "           [ 45.,  46.,  47.,  48.,  49.],\n",
       "           [ 50.,  51.,  52.,  53.,  54.],\n",
       "           [ 55.,  56.,  57.,  58.,  59.]]],\n",
       " \n",
       " \n",
       "         [[[ 60.,  61.,  62.,  63.,  64.],\n",
       "           [ 65.,  66.,  67.,  68.,  69.],\n",
       "           [ 70.,  71.,  72.,  73.,  74.],\n",
       "           [ 75.,  76.,  77.,  78.,  79.]],\n",
       " \n",
       "          [[ 80.,  81.,  82.,  83.,  84.],\n",
       "           [ 85.,  86.,  87.,  88.,  89.],\n",
       "           [ 90.,  91.,  92.,  93.,  94.],\n",
       "           [ 95.,  96.,  97.,  98.,  99.]],\n",
       " \n",
       "          [[100., 101., 102., 103., 104.],\n",
       "           [105., 106., 107., 108., 109.],\n",
       "           [110., 111., 112., 113., 114.],\n",
       "           [115., 116., 117., 118., 420.]]]]))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View of a tensor shares the same memory as the original tensor\n",
    "x_view[7][14] = 420\n",
    "x_view, x_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "84595521-2173-4686-bc52-f2b304bb2167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.8054,  1.0400, -1.1512, -0.6707],\n",
       "         [-0.8812,  0.4081,  1.1452, -0.9442],\n",
       "         [-0.9542, -0.7608, -1.2365, -0.3737]]),\n",
       " torch.Size([3, 4]))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Torch Stack - Concatenates a sequence of tensors along a new dimension\n",
    "s = torch.randn(3, 4)\n",
    "s, s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "68cf6efe-642c-4331-af7a-011417af3768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1.8054],\n",
       "          [ 1.0400],\n",
       "          [-1.1512],\n",
       "          [-0.6707]],\n",
       " \n",
       "         [[-0.8812],\n",
       "          [ 0.4081],\n",
       "          [ 1.1452],\n",
       "          [-0.9442]],\n",
       " \n",
       "         [[-0.9542],\n",
       "          [-0.7608],\n",
       "          [-1.2365],\n",
       "          [-0.3737]]]),\n",
       " torch.Size([3, 4, 1]))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = torch.stack((s,), dim=2)\n",
    "s1, s1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0f451980-99a3-45a8-a6b5-f31c3c2a76f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.8054,  1.0400, -1.1512, -0.6707],\n",
       "         [-0.8812,  0.4081,  1.1452, -0.9442],\n",
       "         [-0.9542, -0.7608, -1.2365, -0.3737]]),\n",
       " torch.Size([3, 4]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.squeeze - removes all single dimensions from a target tensor\n",
    "s2 = s1.squeeze()\n",
    "s2, s2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7fb06dd3-2cee-4357-bae8-e0c05f5c3914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.3390],\n",
       "           [-0.2606],\n",
       "           [-1.3213],\n",
       "           [ 0.6503]],\n",
       " \n",
       "          [[-0.2732],\n",
       "           [-0.4238],\n",
       "           [ 1.3575],\n",
       "           [-1.0860]],\n",
       " \n",
       "          [[-0.5972],\n",
       "           [ 0.1251],\n",
       "           [ 1.6512],\n",
       "           [ 0.4602]]],\n",
       " \n",
       " \n",
       "         [[[ 0.3078],\n",
       "           [-0.2249],\n",
       "           [ 0.1237],\n",
       "           [-0.5064]],\n",
       " \n",
       "          [[ 0.6669],\n",
       "           [-0.4931],\n",
       "           [ 0.5357],\n",
       "           [-0.3753]],\n",
       " \n",
       "          [[ 0.6239],\n",
       "           [ 0.3061],\n",
       "           [ 0.2815],\n",
       "           [ 0.6674]]]]),\n",
       " torch.Size([2, 3, 4, 1]))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valid dim is 0 <= dim < row\n",
    "s3 = torch.randn(2, 3, 4)\n",
    "s3 = s3.unsqueeze(dim=3)\n",
    "s3, s3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2cf06493-4a28-4068-848d-bbf88cffc09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous Shape: torch.Size([224, 224, 3])\n",
      "New Shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# torch.permute - rearrange the diamendions of a target tensor in a specified order\n",
    "# permute is another form of view\n",
    "x_original = torch.rand(size=(224, 224, 3)) # height px, width px, color - RGB\n",
    "\n",
    "# Permute the original tensor to rearrange the axis (or dim) order\n",
    "# i.e shift 2nd index at first\n",
    "x_permuited = x_original.permute(2, 0, 1) # color - RGB, height px, width px\n",
    "print(f\"Previous Shape: {x_original.shape}\")\n",
    "print(f\"New Shape: {x_permuited.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4409377-93be-4022-9163-9b297b985a23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
