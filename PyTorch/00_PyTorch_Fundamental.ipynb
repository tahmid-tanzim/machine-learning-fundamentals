{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0668629e-f135-4a79-8d39-12fda9b1781c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: v2.2.2\n",
      "pandas: v2.2.1\n",
      "numpy: v1.26.4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(f\"torch: v{torch.__version__}\\npandas: v{pd.__version__}\\nnumpy: v{np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dee809-ee80-413d-ad8c-b8d0e00113b0",
   "metadata": {},
   "source": [
    "## Inroduction to Tensors\n",
    "\n",
    "### Creating Tensors\n",
    "\n",
    "https://pytorch.org/docs/stable/tensors.html\n",
    "\n",
    "![Scalar|Vector|Matrix|Tensor](images/svmt.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e088f67-9441-4302-a209-6760bddc6886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar - a single number\n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "162dc08a-6fc0-4b30-a48d-cbcce112eae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c03e6518-08f5-4f27-b1a1-27d87cd68350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dc76928-0264-44da-9d3c-46f1ff76c389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector - a number with direction (e.g. wind speed with direction) but can also have many other numbers\n",
    "\n",
    "vector = torch.tensor([7,7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "231b5c96-6a19-4fb9-abd4-7342d175d688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c356c0f-fed0-42b0-bbaf-ab780118290b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9886f7f3-a13f-4cea-9104-775531ac69e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MATRIX - a 2-dimensional array of numbers\n",
    "MATRIX = torch.tensor([\n",
    "    [7,8],\n",
    "    [9,10]\n",
    "])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c2d7f89-8cb6-40d4-819d-d0049793c82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89b8d598-1dea-4a56-aca9-020acff27ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a36e7a62-ac9b-474d-905b-0b4d7a88fb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3],\n",
       "         [ 4,  5,  6],\n",
       "         [ 7,  8,  9],\n",
       "         [11, 12, 13]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TENSOR - an n-dimensional array of numbers\n",
    "TENSOR = torch.tensor([[\n",
    "    [1,2,3],\n",
    "    [4,5,6],\n",
    "    [7,8,9],\n",
    "    [11,12,13],\n",
    "]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43a13c5b-9b12-4fd0-9cc0-c9b2e2f1b105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80730047-e05a-450a-ba88-8540b0fc5407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9857d794-97ca-45f3-b919-17fab13e15d7",
   "metadata": {},
   "source": [
    "# Scalar | Vector | Matrix | Tensor\n",
    "![Scalar|Vector|Matrix|Tensor](images/00-scalar-vector-matrix-tensor.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c21948c9-db05-4a01-9665-97ec75151ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, torch.Size([2, 3, 4]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(2, 3, 4)\n",
    "random_tensor.ndim, random_tensor.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae88bc86-03c0-46b8-977b-50870a536747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8388, 0.5879, 0.0531, 0.5317],\n",
       "        [0.9509, 0.1559, 0.1383, 0.0595],\n",
       "        [0.1152, 0.2891, 0.6686, 0.9288]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00ef3df8-e9de-449e-9dc7-c2c0c1ad7a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor(1))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range_of_number = torch.arange(0, 10)\n",
    "range_of_number, range_of_number[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3abe6a03-2a4f-4e64-a5e8-641fde041c72",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3., 6., 9.]),\n",
       " torch.float32,\n",
       " device(type='cpu'),\n",
       " False,\n",
       " torch.Size([3]),\n",
       " torch.Size([3]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float 32 tensor\n",
    "float_32_tensor = torch.tensor(\n",
    "    [3.0, 6.0, 9.0],\n",
    "    dtype=torch.float32,\n",
    "    device='cpu',\n",
    "    requires_grad=False)\n",
    "\n",
    "(\n",
    "    float_32_tensor,\n",
    "    float_32_tensor.dtype,\n",
    "    float_32_tensor.device,\n",
    "    float_32_tensor.requires_grad,\n",
    "    float_32_tensor.shape,\n",
    "    float_32_tensor.size(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6aa0bbbe-c090-4af3-ae71-e31424a67537",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3., 6., 9.], dtype=torch.float16),\n",
       " torch.float16,\n",
       " device(type='cpu'),\n",
       " False,\n",
       " torch.Size([3]),\n",
       " torch.Size([3]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.float16)\n",
    "\n",
    "(\n",
    "    float_16_tensor,\n",
    "    float_16_tensor.dtype,\n",
    "    float_16_tensor.device,\n",
    "    float_16_tensor.requires_grad,\n",
    "    float_16_tensor.shape,\n",
    "    float_16_tensor.size(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b67adb9-40dd-4f7e-800b-d71ab058e758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor * float_32_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ef17a1-9335-4e87-81fd-4b603bf48ab6",
   "metadata": {},
   "source": [
    "### Manipulation Tensors (tensor operation)\n",
    "\n",
    "* Addition\n",
    "* Subtraction\n",
    "* Division\n",
    "* Multiplacation (element-wise)\n",
    "* Matrix Multiplication\n",
    "\n",
    "#### The main two rules for matrix multiplication to remember are:\n",
    "\n",
    "1. The inner dimensions must match:\n",
    "(3, 2) @ (3, 2) won't work\n",
    "(2, 3) @ (3, 2) will work\n",
    "(3, 2) @ (2, 3) will work\n",
    "\n",
    "2. The resulting matrix has the shape of the outer dimensions:\n",
    "(2, 3) @ (3, 2) -> (2, 2)\n",
    "(3, 2) @ (2, 3) -> (3, 3)\n",
    "\n",
    "\n",
    "![Matrix Multiplacation](images/matrix-multiplication.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "849f77a0-7867-4a7b-8780-60d2fef0d5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[140, 146],\n",
       "        [320, 335]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_a = torch.tensor([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "])\n",
    "\n",
    "matrix_b = torch.tensor([\n",
    "    [10, 11],\n",
    "    [20, 21],\n",
    "    [30, 31],\n",
    "])\n",
    "\n",
    "matrix_ab = torch.matmul(matrix_a, matrix_b)\n",
    "matrix_ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2533edb6-f152-4415-9a7b-8e0e82bae20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
      "\n",
      "New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])\n",
      "\n",
      "Multiplying: torch.Size([3, 2]) * torch.Size([2, 3]) <- inner dimensions match\n",
      "\n",
      "Output:\n",
      "\n",
      "tensor([[ 27.,  30.,  33.],\n",
      "        [ 61.,  68.,  75.],\n",
      "        [ 95., 106., 117.]])\n",
      "\n",
      "Output shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Shapes need to be in the right way  \n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]], dtype=torch.float32)\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                         [8, 11], \n",
    "                         [9, 12]], dtype=torch.float32)\n",
    "# The operation works when tensor_B is transposed\n",
    "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\")\n",
    "print(f\"New shapes: tensor_A = {tensor_A.shape} (same as above), tensor_B.T = {tensor_B.T.shape}\\n\")\n",
    "print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape} <- inner dimensions match\\n\")\n",
    "print(\"Output:\\n\")\n",
    "output = torch.matmul(tensor_A, tensor_B.T)\n",
    "print(output) \n",
    "print(f\"\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f059e4-7585-4118-ba37-c0a7c13d7082",
   "metadata": {},
   "source": [
    "### Reshaping, stacking, squeezing and unsqueezing\n",
    "Often times you'll want to reshape or change the dimensions of your tensors without actually changing the values inside them.\n",
    "\n",
    "To do so, some popular methods are:\n",
    "\n",
    "| Method                        | One-line description                                                                                        |\n",
    "|-------------------------------|-------------------------------------------------------------------------------------------------------------|\n",
    "| `torch.reshape(input, shape)` | Reshapes input to shape (if compatible), can also use torch.Tensor.reshape().                               |\n",
    "| `Tensor.view(shape)`          | Returns a view of the original tensor in a different shape but shares the same data as the original tensor. |\n",
    "| `torch.stack(tensors, dim=0)` | Concatenates a sequence of tensors along a new dimension (dim), all tensors must be same size.              |\n",
    "| `torch.squeeze(input)`        | Squeezes input to remove all the dimenions with value 1.                                                    |\n",
    "| `torch.unsqueeze(input, dim)` | Returns input with a dimension value of 1 added at dim.                                                     |\n",
    "| `torch.permute(input, dims)`  | Returns a view of the original input with its dimensions permuted (rearranged) to dims.                     |\n",
    "\n",
    "Why do any of these?\n",
    "\n",
    "Because deep learning models (neural networks) are all about manipulating tensors in some way. And because of the rules of matrix multiplication, if you've got shape mismatches, you'll run into errors. These methods help you make sure the right elements of your tensors are mixing with the right elements of other tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f15635c2-749b-47ce-ae1b-eb1104c6d0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,  11.,\n",
       "          12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.,  21.,  22.,  23.,\n",
       "          24.,  25.,  26.,  27.,  28.,  29.,  30.,  31.,  32.,  33.,  34.,  35.,\n",
       "          36.,  37.,  38.,  39.,  40.,  41.,  42.,  43.,  44.,  45.,  46.,  47.,\n",
       "          48.,  49.,  50.,  51.,  52.,  53.,  54.,  55.,  56.,  57.,  58.,  59.,\n",
       "          60.,  61.,  62.,  63.,  64.,  65.,  66.,  67.,  68.,  69.,  70.,  71.,\n",
       "          72.,  73.,  74.,  75.,  76.,  77.,  78.,  79.,  80.,  81.,  82.,  83.,\n",
       "          84.,  85.,  86.,  87.,  88.,  89.,  90.,  91.,  92.,  93.,  94.,  95.,\n",
       "          96.,  97.,  98.,  99., 100., 101., 102., 103., 104., 105., 106., 107.,\n",
       "         108., 109., 110., 111., 112., 113., 114., 115., 116., 117., 118., 119.]),\n",
       " torch.Size([120]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(120.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ce262c2-8118-489e-8728-f72aa8c70f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[  0.,   1.,   2.,   3.,   4.],\n",
       "           [  5.,   6.,   7.,   8.,   9.],\n",
       "           [ 10.,  11.,  12.,  13.,  14.],\n",
       "           [ 15.,  16.,  17.,  18.,  19.]],\n",
       " \n",
       "          [[ 20.,  21.,  22.,  23.,  24.],\n",
       "           [ 25.,  26.,  27.,  28.,  29.],\n",
       "           [ 30.,  31.,  32.,  33.,  34.],\n",
       "           [ 35.,  36.,  37.,  38.,  39.]],\n",
       " \n",
       "          [[ 40.,  41.,  42.,  43.,  44.],\n",
       "           [ 45.,  46.,  47.,  48.,  49.],\n",
       "           [ 50.,  51.,  52.,  53.,  54.],\n",
       "           [ 55.,  56.,  57.,  58.,  59.]]],\n",
       " \n",
       " \n",
       "         [[[ 60.,  61.,  62.,  63.,  64.],\n",
       "           [ 65.,  66.,  67.,  68.,  69.],\n",
       "           [ 70.,  71.,  72.,  73.,  74.],\n",
       "           [ 75.,  76.,  77.,  78.,  79.]],\n",
       " \n",
       "          [[ 80.,  81.,  82.,  83.,  84.],\n",
       "           [ 85.,  86.,  87.,  88.,  89.],\n",
       "           [ 90.,  91.,  92.,  93.,  94.],\n",
       "           [ 95.,  96.,  97.,  98.,  99.]],\n",
       " \n",
       "          [[100., 101., 102., 103., 104.],\n",
       "           [105., 106., 107., 108., 109.],\n",
       "           [110., 111., 112., 113., 114.],\n",
       "           [115., 116., 117., 118., 119.]]]]),\n",
       " torch.Size([2, 3, 4, 5]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped = torch.reshape(x, (2, 3, 4, 5))\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64687c50-1566-4fb4-96d2-8a1aa9161867",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
