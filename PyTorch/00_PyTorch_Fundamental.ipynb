{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0668629e-f135-4a79-8d39-12fda9b1781c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: v2.2.2\n",
      "pandas: v2.2.1\n",
      "numpy: v1.26.4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(f\"torch: v{torch.__version__}\\npandas: v{pd.__version__}\\nnumpy: v{np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dee809-ee80-413d-ad8c-b8d0e00113b0",
   "metadata": {},
   "source": [
    "## Inroduction to Tensors\n",
    "\n",
    "### Creating Tensors\n",
    "\n",
    "https://pytorch.org/docs/stable/tensors.html\n",
    "\n",
    "![Scalar|Vector|Matrix|Tensor](images/svmt.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7e088f67-9441-4302-a209-6760bddc6886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar - a single number\n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "162dc08a-6fc0-4b30-a48d-cbcce112eae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c03e6518-08f5-4f27-b1a1-27d87cd68350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0dc76928-0264-44da-9d3c-46f1ff76c389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector - a number with direction (e.g. wind speed with direction) but can also have many other numbers\n",
    "\n",
    "vector = torch.tensor([7,7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "231b5c96-6a19-4fb9-abd4-7342d175d688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2c356c0f-fed0-42b0-bbaf-ab780118290b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9886f7f3-a13f-4cea-9104-775531ac69e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MATRIX - a 2-dimensional array of numbers\n",
    "MATRIX = torch.tensor([\n",
    "    [7,8],\n",
    "    [9,10]\n",
    "])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9c2d7f89-8cb6-40d4-819d-d0049793c82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "89b8d598-1dea-4a56-aca9-020acff27ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a36e7a62-ac9b-474d-905b-0b4d7a88fb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3],\n",
       "         [ 4,  5,  6],\n",
       "         [ 7,  8,  9],\n",
       "         [11, 12, 13]]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TENSOR - an n-dimensional array of numbers\n",
    "TENSOR = torch.tensor([[\n",
    "    [1,2,3],\n",
    "    [4,5,6],\n",
    "    [7,8,9],\n",
    "    [11,12,13],\n",
    "]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "43a13c5b-9b12-4fd0-9cc0-c9b2e2f1b105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "80730047-e05a-450a-ba88-8540b0fc5407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 3])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9857d794-97ca-45f3-b919-17fab13e15d7",
   "metadata": {},
   "source": [
    "# Scalar | Vector | Matrix | Tensor\n",
    "![Scalar|Vector|Matrix|Tensor](images/00-scalar-vector-matrix-tensor.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c21948c9-db05-4a01-9665-97ec75151ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, torch.Size([2, 3, 4]))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(2, 3, 4)\n",
    "random_tensor.ndim, random_tensor.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ae88bc86-03c0-46b8-977b-50870a536747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3813, 0.4937, 0.7975, 0.6947],\n",
       "        [0.6742, 0.6710, 0.7174, 0.6410],\n",
       "        [0.0750, 0.3849, 0.6500, 0.3122]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "00ef3df8-e9de-449e-9dc7-c2c0c1ad7a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor(1))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range_of_number = torch.arange(0, 10)\n",
    "range_of_number, range_of_number[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3abe6a03-2a4f-4e64-a5e8-641fde041c72",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3., 6., 9.]),\n",
       " torch.float32,\n",
       " device(type='cpu'),\n",
       " False,\n",
       " torch.Size([3]),\n",
       " torch.Size([3]))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float 32 tensor\n",
    "float_32_tensor = torch.tensor(\n",
    "    [3.0, 6.0, 9.0],\n",
    "    dtype=torch.float32,\n",
    "    device='cpu',\n",
    "    requires_grad=False)\n",
    "\n",
    "(\n",
    "    float_32_tensor,\n",
    "    float_32_tensor.dtype,\n",
    "    float_32_tensor.device,\n",
    "    float_32_tensor.requires_grad,\n",
    "    float_32_tensor.shape,\n",
    "    float_32_tensor.size(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6aa0bbbe-c090-4af3-ae71-e31424a67537",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3., 6., 9.], dtype=torch.float16),\n",
       " torch.float16,\n",
       " device(type='cpu'),\n",
       " False,\n",
       " torch.Size([3]),\n",
       " torch.Size([3]))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.float16)\n",
    "\n",
    "(\n",
    "    float_16_tensor,\n",
    "    float_16_tensor.dtype,\n",
    "    float_16_tensor.device,\n",
    "    float_16_tensor.requires_grad,\n",
    "    float_16_tensor.shape,\n",
    "    float_16_tensor.size(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3b67adb9-40dd-4f7e-800b-d71ab058e758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor * float_32_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ef17a1-9335-4e87-81fd-4b603bf48ab6",
   "metadata": {},
   "source": [
    "### Manipulation Tensors (tensor operation)\n",
    "\n",
    "* Addition\n",
    "* Subtraction\n",
    "* Division\n",
    "* Multiplacation (element-wise)\n",
    "* Matrix Multiplication\n",
    "\n",
    "#### The main two rules for matrix multiplication to remember are:\n",
    "\n",
    "1. The inner dimensions must match:\n",
    "(3, 2) @ (3, 2) won't work\n",
    "(2, 3) @ (3, 2) will work\n",
    "(3, 2) @ (2, 3) will work\n",
    "\n",
    "2. The resulting matrix has the shape of the outer dimensions:\n",
    "(2, 3) @ (3, 2) -> (2, 2)\n",
    "(3, 2) @ (2, 3) -> (3, 3)\n",
    "\n",
    "\n",
    "![Matrix Multiplacation](images/matrix-multiplication.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "849f77a0-7867-4a7b-8780-60d2fef0d5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[140, 146],\n",
       "        [320, 335]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_a = torch.tensor([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "])\n",
    "\n",
    "matrix_b = torch.tensor([\n",
    "    [10, 11],\n",
    "    [20, 21],\n",
    "    [30, 31],\n",
    "])\n",
    "\n",
    "matrix_ab = torch.matmul(matrix_a, matrix_b)\n",
    "matrix_ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2533edb6-f152-4415-9a7b-8e0e82bae20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
      "\n",
      "New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])\n",
      "\n",
      "Multiplying: torch.Size([3, 2]) * torch.Size([2, 3]) <- inner dimensions match\n",
      "\n",
      "Output:\n",
      "\n",
      "tensor([[ 27.,  30.,  33.],\n",
      "        [ 61.,  68.,  75.],\n",
      "        [ 95., 106., 117.]])\n",
      "\n",
      "Output shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Shapes need to be in the right way  \n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]], dtype=torch.float32)\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                         [8, 11], \n",
    "                         [9, 12]], dtype=torch.float32)\n",
    "# The operation works when tensor_B is transposed\n",
    "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\")\n",
    "print(f\"New shapes: tensor_A = {tensor_A.shape} (same as above), tensor_B.T = {tensor_B.T.shape}\\n\")\n",
    "print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape} <- inner dimensions match\\n\")\n",
    "print(\"Output:\\n\")\n",
    "output = torch.matmul(tensor_A, tensor_B.T)\n",
    "print(output) \n",
    "print(f\"\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f059e4-7585-4118-ba37-c0a7c13d7082",
   "metadata": {},
   "source": [
    "### Reshaping, stacking, squeezing and unsqueezing\n",
    "Often times you'll want to reshape or change the dimensions of your tensors without actually changing the values inside them.\n",
    "\n",
    "To do so, some popular methods are:\n",
    "\n",
    "| Method                        | One-line description                                                                                        |\n",
    "|-------------------------------|-------------------------------------------------------------------------------------------------------------|\n",
    "| `torch.reshape(input, shape)` | Reshapes input to shape (if compatible), can also use torch.Tensor.reshape().                               |\n",
    "| `Tensor.view(shape)`          | Returns a view of the original tensor in a different shape but shares the same data as the original tensor. |\n",
    "| `torch.stack(tensors, dim=0)` | Concatenates a sequence of tensors along a new dimension (dim), all tensors must be same size.              |\n",
    "| `torch.squeeze(input)`        | Squeezes input to remove all the dimenions with value 1.                                                    |\n",
    "| `torch.unsqueeze(input, dim)` | Returns input with a dimension value of 1 added at dim.                                                     |\n",
    "| `torch.permute(input, dims)`  | Returns a view of the original input with its dimensions permuted (rearranged) to dims.                     |\n",
    "\n",
    "Why do any of these?\n",
    "\n",
    "Because deep learning models (neural networks) are all about manipulating tensors in some way. And because of the rules of matrix multiplication, if you've got shape mismatches, you'll run into errors. These methods help you make sure the right elements of your tensors are mixing with the right elements of other tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f15635c2-749b-47ce-ae1b-eb1104c6d0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,  11.,\n",
       "          12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.,  21.,  22.,  23.,\n",
       "          24.,  25.,  26.,  27.,  28.,  29.,  30.,  31.,  32.,  33.,  34.,  35.,\n",
       "          36.,  37.,  38.,  39.,  40.,  41.,  42.,  43.,  44.,  45.,  46.,  47.,\n",
       "          48.,  49.,  50.,  51.,  52.,  53.,  54.,  55.,  56.,  57.,  58.,  59.,\n",
       "          60.,  61.,  62.,  63.,  64.,  65.,  66.,  67.,  68.,  69.,  70.,  71.,\n",
       "          72.,  73.,  74.,  75.,  76.,  77.,  78.,  79.,  80.,  81.,  82.,  83.,\n",
       "          84.,  85.,  86.,  87.,  88.,  89.,  90.,  91.,  92.,  93.,  94.,  95.,\n",
       "          96.,  97.,  98.,  99., 100., 101., 102., 103., 104., 105., 106., 107.,\n",
       "         108., 109., 110., 111., 112., 113., 114., 115., 116., 117., 118., 119.]),\n",
       " torch.Size([120]))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Torch Reshape - https://pytorch.org/docs/stable/generated/torch.reshape.html\n",
    "x = torch.arange(120.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8ce262c2-8118-489e-8728-f72aa8c70f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[  0.,   1.,   2.,   3.,   4.],\n",
       "           [  5.,   6.,   7.,   8.,   9.],\n",
       "           [ 10.,  11.,  12.,  13.,  14.],\n",
       "           [ 15.,  16.,  17.,  18.,  19.]],\n",
       " \n",
       "          [[ 20.,  21.,  22.,  23.,  24.],\n",
       "           [ 25.,  26.,  27.,  28.,  29.],\n",
       "           [ 30.,  31.,  32.,  33.,  34.],\n",
       "           [ 35.,  36.,  37.,  38.,  39.]],\n",
       " \n",
       "          [[ 40.,  41.,  42.,  43.,  44.],\n",
       "           [ 45.,  46.,  47.,  48.,  49.],\n",
       "           [ 50.,  51.,  52.,  53.,  54.],\n",
       "           [ 55.,  56.,  57.,  58.,  59.]]],\n",
       " \n",
       " \n",
       "         [[[ 60.,  61.,  62.,  63.,  64.],\n",
       "           [ 65.,  66.,  67.,  68.,  69.],\n",
       "           [ 70.,  71.,  72.,  73.,  74.],\n",
       "           [ 75.,  76.,  77.,  78.,  79.]],\n",
       " \n",
       "          [[ 80.,  81.,  82.,  83.,  84.],\n",
       "           [ 85.,  86.,  87.,  88.,  89.],\n",
       "           [ 90.,  91.,  92.,  93.,  94.],\n",
       "           [ 95.,  96.,  97.,  98.,  99.]],\n",
       " \n",
       "          [[100., 101., 102., 103., 104.],\n",
       "           [105., 106., 107., 108., 109.],\n",
       "           [110., 111., 112., 113., 114.],\n",
       "           [115., 116., 117., 118., 119.]]]]),\n",
       " torch.Size([2, 3, 4, 5]))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Torch Reshape - https://pytorch.org/docs/stable/generated/torch.reshape.html\n",
    "x_reshaped = torch.reshape(x, (2, 3, 4, 5))\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "64687c50-1566-4fb4-96d2-8a1aa9161867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,  11.,\n",
       "           12.,  13.,  14.],\n",
       "         [ 15.,  16.,  17.,  18.,  19.,  20.,  21.,  22.,  23.,  24.,  25.,  26.,\n",
       "           27.,  28.,  29.],\n",
       "         [ 30.,  31.,  32.,  33.,  34.,  35.,  36.,  37.,  38.,  39.,  40.,  41.,\n",
       "           42.,  43.,  44.],\n",
       "         [ 45.,  46.,  47.,  48.,  49.,  50.,  51.,  52.,  53.,  54.,  55.,  56.,\n",
       "           57.,  58.,  59.],\n",
       "         [ 60.,  61.,  62.,  63.,  64.,  65.,  66.,  67.,  68.,  69.,  70.,  71.,\n",
       "           72.,  73.,  74.],\n",
       "         [ 75.,  76.,  77.,  78.,  79.,  80.,  81.,  82.,  83.,  84.,  85.,  86.,\n",
       "           87.,  88.,  89.],\n",
       "         [ 90.,  91.,  92.,  93.,  94.,  95.,  96.,  97.,  98.,  99., 100., 101.,\n",
       "          102., 103., 104.],\n",
       "         [105., 106., 107., 108., 109., 110., 111., 112., 113., 114., 115., 116.,\n",
       "          117., 118., 119.]]),\n",
       " torch.Size([8, 15]))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://pytorch.org/docs/stable/generated/torch.Tensor.view.html\n",
    "x_view = x_reshaped.view(8, 15)\n",
    "x_view, x_view.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b53085f8-ea58-4a24-b3be-d7c5d882b5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,  11.,\n",
       "           12.,  13.,  14.],\n",
       "         [ 15.,  16.,  17.,  18.,  19.,  20.,  21.,  22.,  23.,  24.,  25.,  26.,\n",
       "           27.,  28.,  29.],\n",
       "         [ 30.,  31.,  32.,  33.,  34.,  35.,  36.,  37.,  38.,  39.,  40.,  41.,\n",
       "           42.,  43.,  44.],\n",
       "         [ 45.,  46.,  47.,  48.,  49.,  50.,  51.,  52.,  53.,  54.,  55.,  56.,\n",
       "           57.,  58.,  59.],\n",
       "         [ 60.,  61.,  62.,  63.,  64.,  65.,  66.,  67.,  68.,  69.,  70.,  71.,\n",
       "           72.,  73.,  74.],\n",
       "         [ 75.,  76.,  77.,  78.,  79.,  80.,  81.,  82.,  83.,  84.,  85.,  86.,\n",
       "           87.,  88.,  89.],\n",
       "         [ 90.,  91.,  92.,  93.,  94.,  95.,  96.,  97.,  98.,  99., 100., 101.,\n",
       "          102., 103., 104.],\n",
       "         [105., 106., 107., 108., 109., 110., 111., 112., 113., 114., 115., 116.,\n",
       "          117., 118., 420.]]),\n",
       " tensor([[[[  0.,   1.,   2.,   3.,   4.],\n",
       "           [  5.,   6.,   7.,   8.,   9.],\n",
       "           [ 10.,  11.,  12.,  13.,  14.],\n",
       "           [ 15.,  16.,  17.,  18.,  19.]],\n",
       " \n",
       "          [[ 20.,  21.,  22.,  23.,  24.],\n",
       "           [ 25.,  26.,  27.,  28.,  29.],\n",
       "           [ 30.,  31.,  32.,  33.,  34.],\n",
       "           [ 35.,  36.,  37.,  38.,  39.]],\n",
       " \n",
       "          [[ 40.,  41.,  42.,  43.,  44.],\n",
       "           [ 45.,  46.,  47.,  48.,  49.],\n",
       "           [ 50.,  51.,  52.,  53.,  54.],\n",
       "           [ 55.,  56.,  57.,  58.,  59.]]],\n",
       " \n",
       " \n",
       "         [[[ 60.,  61.,  62.,  63.,  64.],\n",
       "           [ 65.,  66.,  67.,  68.,  69.],\n",
       "           [ 70.,  71.,  72.,  73.,  74.],\n",
       "           [ 75.,  76.,  77.,  78.,  79.]],\n",
       " \n",
       "          [[ 80.,  81.,  82.,  83.,  84.],\n",
       "           [ 85.,  86.,  87.,  88.,  89.],\n",
       "           [ 90.,  91.,  92.,  93.,  94.],\n",
       "           [ 95.,  96.,  97.,  98.,  99.]],\n",
       " \n",
       "          [[100., 101., 102., 103., 104.],\n",
       "           [105., 106., 107., 108., 109.],\n",
       "           [110., 111., 112., 113., 114.],\n",
       "           [115., 116., 117., 118., 420.]]]]))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View of a tensor shares the same memory as the original tensor\n",
    "x_view[7][14] = 420\n",
    "x_view, x_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "84595521-2173-4686-bc52-f2b304bb2167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.1884, -0.4684,  0.1036,  0.0903],\n",
       "         [ 0.4505,  0.4147,  0.2110,  0.7234],\n",
       "         [-0.7373, -0.4509, -1.3649,  0.0669]]),\n",
       " torch.Size([3, 4]))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Torch Stack - Concatenates a sequence of tensors along a new dimension\n",
    "s = torch.randn(3, 4)\n",
    "s, s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "68cf6efe-642c-4331-af7a-011417af3768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.1884],\n",
       "          [-0.4684],\n",
       "          [ 0.1036],\n",
       "          [ 0.0903]],\n",
       " \n",
       "         [[ 0.4505],\n",
       "          [ 0.4147],\n",
       "          [ 0.2110],\n",
       "          [ 0.7234]],\n",
       " \n",
       "         [[-0.7373],\n",
       "          [-0.4509],\n",
       "          [-1.3649],\n",
       "          [ 0.0669]]]),\n",
       " torch.Size([3, 4, 1]))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = torch.stack((s,), dim=2)\n",
    "s1, s1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0f451980-99a3-45a8-a6b5-f31c3c2a76f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.1884, -0.4684,  0.1036,  0.0903],\n",
       "         [ 0.4505,  0.4147,  0.2110,  0.7234],\n",
       "         [-0.7373, -0.4509, -1.3649,  0.0669]]),\n",
       " torch.Size([3, 4]))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.squeeze - removes all single dimensions from a target tensor\n",
    "s2 = s1.squeeze()\n",
    "s2, s2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7fb06dd3-2cee-4357-bae8-e0c05f5c3914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.6464],\n",
       "           [ 1.0264],\n",
       "           [ 0.4277],\n",
       "           [ 2.5017]],\n",
       " \n",
       "          [[-1.6657],\n",
       "           [ 1.5276],\n",
       "           [ 0.3070],\n",
       "           [-1.2935]],\n",
       " \n",
       "          [[ 0.5641],\n",
       "           [-0.6883],\n",
       "           [ 1.5459],\n",
       "           [ 1.3052]]],\n",
       " \n",
       " \n",
       "         [[[-1.9791],\n",
       "           [-0.3833],\n",
       "           [-0.4383],\n",
       "           [-1.2587]],\n",
       " \n",
       "          [[ 1.2984],\n",
       "           [-0.3189],\n",
       "           [-0.6529],\n",
       "           [ 0.1451]],\n",
       " \n",
       "          [[ 0.0842],\n",
       "           [ 1.0583],\n",
       "           [ 0.3804],\n",
       "           [-0.1970]]]]),\n",
       " torch.Size([2, 3, 4, 1]))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valid dim is 0 <= dim < row\n",
    "s3 = torch.randn(2, 3, 4)\n",
    "s3 = s3.unsqueeze(dim=3)\n",
    "s3, s3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2cf06493-4a28-4068-848d-bbf88cffc09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous Shape: torch.Size([224, 224, 3])\n",
      "New Shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# torch.permute - rearrange the diamendions of a target tensor in a specified order\n",
    "x_original = torch.rand(size=(224, 224, 3)) # height px, width px, color - RGB\n",
    "\n",
    "# Permute the original tensor to rearrange the axis (or dim) order\n",
    "# i.e shift 2nd index at first\n",
    "x_permuted = x_original.permute(2, 0, 1) # color - RGB, height px, width px\n",
    "print(f\"Previous Shape: {x_original.shape}\")\n",
    "print(f\"New Shape: {x_permuted.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f4409377-93be-4022-9163-9b297b985a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.2300e+02, 8.9718e-01, 8.8294e-01,  ..., 4.6177e-01,\n",
       "          5.6759e-02, 6.1637e-01],\n",
       "         [3.1799e-01, 5.8563e-01, 1.5749e-01,  ..., 3.1214e-02,\n",
       "          4.3181e-01, 3.1763e-01],\n",
       "         [9.8469e-02, 2.6017e-01, 2.1782e-01,  ..., 2.9206e-01,\n",
       "          5.7326e-01, 3.1044e-01],\n",
       "         ...,\n",
       "         [1.8289e-01, 5.6318e-01, 4.3357e-01,  ..., 6.1456e-01,\n",
       "          5.5831e-01, 2.8226e-01],\n",
       "         [4.6256e-01, 2.0003e-01, 8.9312e-01,  ..., 4.0309e-01,\n",
       "          7.9244e-01, 6.5863e-01],\n",
       "         [2.0825e-01, 8.6543e-01, 6.1006e-01,  ..., 4.4326e-01,\n",
       "          7.2815e-01, 4.5644e-01]],\n",
       "\n",
       "        [[3.5764e-01, 7.4956e-01, 9.7185e-01,  ..., 3.9514e-01,\n",
       "          7.5380e-02, 5.1866e-02],\n",
       "         [7.9816e-02, 2.8220e-01, 3.6376e-01,  ..., 8.8540e-01,\n",
       "          6.9155e-01, 4.4812e-02],\n",
       "         [1.5864e-01, 9.9441e-01, 6.6870e-03,  ..., 3.4789e-01,\n",
       "          7.1704e-01, 1.6931e-01],\n",
       "         ...,\n",
       "         [4.1672e-01, 8.5981e-01, 2.2194e-01,  ..., 7.2428e-01,\n",
       "          9.3685e-01, 7.0542e-01],\n",
       "         [3.9686e-01, 4.5883e-01, 3.9334e-01,  ..., 5.4313e-01,\n",
       "          6.0667e-01, 7.0831e-01],\n",
       "         [4.5872e-01, 3.6044e-01, 5.0308e-01,  ..., 1.3014e-01,\n",
       "          3.9871e-01, 5.6209e-01]],\n",
       "\n",
       "        [[3.1296e-01, 2.4332e-02, 4.8276e-01,  ..., 7.2118e-01,\n",
       "          9.4983e-01, 2.6082e-01],\n",
       "         [6.5652e-01, 9.1477e-01, 3.3566e-01,  ..., 6.9361e-01,\n",
       "          9.3288e-01, 9.1249e-01],\n",
       "         [4.1964e-01, 6.0418e-01, 2.5061e-01,  ..., 9.4975e-01,\n",
       "          8.5024e-01, 5.7795e-01],\n",
       "         ...,\n",
       "         [7.7999e-01, 2.8537e-02, 2.1197e-01,  ..., 7.4752e-01,\n",
       "          5.3691e-01, 5.7989e-02],\n",
       "         [4.8566e-01, 1.3515e-01, 8.5402e-02,  ..., 3.0902e-01,\n",
       "          1.1138e-01, 6.8271e-02],\n",
       "         [4.8672e-01, 9.6100e-01, 4.8542e-01,  ..., 8.3237e-01,\n",
       "          3.7372e-01, 6.9974e-01]]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As permute is another form of view\n",
    "x_original[0, 0, 0] = 123\n",
    "x_permuted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92cdd98-b4b5-4244-a4ee-e8aafb18527e",
   "metadata": {},
   "source": [
    "# PyTorch tensors & NumPy\n",
    "Since NumPy is a popular Python numerical computing library, PyTorch has functionality to interact with it nicely.\n",
    "\n",
    "The two main methods you'll want to use for NumPy to PyTorch (and back again) are:\n",
    "\n",
    "* torch.from_numpy(ndarray) - NumPy array -> PyTorch tensor.\n",
    "* torch.Tensor.numpy() - PyTorch tensor -> NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "596ecbd8-0a4b-4426-8b9a-0d5831804908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Numpy Array to Tensor\n",
    "np_array = np.arange(1, 13)\n",
    "tensor_array = torch.from_numpy(np_array).type(torch.float32)\n",
    "tensor_array, tensor_array.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a275db02-0ee7-4bfc-9115-c38e6943d404",
   "metadata": {},
   "source": [
    "Note: By default, NumPy arrays are created with the datatype float64 and if you convert it to a PyTorch tensor, it'll keep the same datatype (as above).\n",
    "\n",
    "However, many PyTorch calculations default to using float32.\n",
    "\n",
    "So if you want to convert your NumPy array (float64) -> PyTorch tensor (float64) -> PyTorch tensor (float32), you can use tensor = torch.from_numpy(array).type(torch.float32)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "fef5f70d-8642-4593-95af-5067c4a8c310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.208 , -0.853 ,  2.361 ],\n",
       "       [ 0.4146,  1.675 , -1.122 ],\n",
       "       [ 0.2866, -0.4272,  1.474 ],\n",
       "       [-0.4614, -1.48  ,  1.289 ],\n",
       "       [-0.1599,  0.555 , -0.731 ]], dtype=float16)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Tensor to NumPy\n",
    "tensor_array_2 = torch.randn(5, 3).type(torch.float16)\n",
    "np_array_2 = tensor_array_2.numpy()\n",
    "np_array_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676622d4-2d0f-466d-a412-1968d635af77",
   "metadata": {},
   "source": [
    "# Reproducibility (trying to take the random out of random)\n",
    "\n",
    "Reference Link - [https://pytorch.org/docs/stable/notes/randomness.html](https://pytorch.org/docs/stable/notes/randomness.html)\n",
    "\n",
    "Random Seed [https://en.wikipedia.org/wiki/Random_seed](https://en.wikipedia.org/wiki/Random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "91f172cc-a169-495a-8a12-223487a60ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor A:\n",
      "tensor([[0.5980, 0.2668, 0.2344, 0.8088],\n",
      "        [0.5446, 0.2481, 0.3540, 0.0569],\n",
      "        [0.3095, 0.4791, 0.6095, 0.1208]])\n",
      "\n",
      "Tensor B:\n",
      "tensor([[0.8841, 0.0487, 0.4038, 0.3893],\n",
      "        [0.5358, 0.7485, 0.3455, 0.9184],\n",
      "        [0.2425, 0.9557, 0.4760, 0.6909]])\n",
      "\n",
      "Does Tensor A equal Tensor B? (anywhere)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create two random tensors\n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Tensor A:\\n{random_tensor_A}\\n\")\n",
    "print(f\"Tensor B:\\n{random_tensor_B}\\n\")\n",
    "print(f\"Does Tensor A equal Tensor B? (anywhere)\")\n",
    "random_tensor_A == random_tensor_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e3537f5b-d486-4168-94db-6da8320622aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor C:\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "\n",
      "Tensor D:\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "\n",
      "Does Tensor C equal Tensor D? (anywhere)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the random seed\n",
    "RANDOM_SEED=42 # try changing this to different values and see what happens to the numbers below\n",
    "torch.manual_seed(seed=RANDOM_SEED) \n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "# Have to reset the seed every time a new rand() is called \n",
    "# Without this, tensor_D would be different to tensor_C \n",
    "torch.manual_seed(seed=RANDOM_SEED) # try commenting this line out and seeing what happens\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Tensor C:\\n{random_tensor_C}\\n\")\n",
    "print(f\"Tensor D:\\n{random_tensor_D}\\n\")\n",
    "print(f\"Does Tensor C equal Tensor D? (anywhere)\")\n",
    "random_tensor_C == random_tensor_D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cba3ff9-f5ed-4830-8f4e-471e024b346e",
   "metadata": {},
   "source": [
    "# Accessing a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c51dbc3a-6e9f-4ae3-9794-bdd7b82bc804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# verify mps support - https://developer.apple.com/metal/pytorch/\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8bfa5875-9266-4b4b-a801-2fc91ca9ce61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8e19318c-4cff-4668-8aa4-7acf7aedffc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU : --- 0.16501903533935547 seconds ---\n",
      "MPS : --- 0.00024199485778808594 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# toy example mps\n",
    "import time\n",
    "\n",
    "device = \"mps\"\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "TENSOR_A_CPU = torch.rand(5000, 5000)\n",
    "TENSOR_B_CPU = torch.rand(5000, 5000)\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "TENSOR_A_MPS = torch.rand(5000, 5000).to(device)\n",
    "TENSOR_B_MPS = torch.rand(5000, 5000).to(device)\n",
    "\n",
    "# Warm-up\n",
    "for _ in range(100):\n",
    "    torch.matmul(torch.rand(500,500).to(device), torch.rand(500,500).to(device))\n",
    "    \n",
    "start_time = time.time()\n",
    "torch.matmul(TENSOR_A_CPU, TENSOR_B_CPU)\n",
    "print(\"CPU : --- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "torch.matmul(TENSOR_A_MPS, TENSOR_B_MPS)\n",
    "print(\"MPS : --- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462afffd-644f-4ff1-90af-bc5f3ca7e123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ea887c-7f80-4117-a2a9-ed9e37734cf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
